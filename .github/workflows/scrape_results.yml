name: Scrape AFL results

on:
  schedule:
    - cron: '0 0 * * *'  # midnight UTC daily = ~10am AEST / ~11am AEDT
  workflow_dispatch:      # also triggerable manually from the GitHub Actions UI

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    permissions:
      contents: write

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install requests beautifulsoup4 pandas lxml

      - name: Run scraper
        run: python scrape_afl_tables.py 2>&1 | tee scrape_output.log

      - name: Fail if all new matches errored
        run: |
          if grep -q "FAIL" scrape_output.log && ! grep -q "] OK " scrape_output.log; then
            echo "::error::All new match scrapes failed — check AFL Tables availability."
            exit 1
          fi

      - name: Commit updated data if changed
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add afl_team_rows.csv
          if git diff --staged --quiet; then
            echo "No new match data — nothing to commit."
          else
            git commit -m "Auto-update: afl_team_rows.csv ($(date -u '+%Y-%m-%d'))"
            git push
          fi
